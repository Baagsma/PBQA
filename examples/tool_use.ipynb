{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"temperature\": 15.5,\n",
      "    \"precipitation_probability\": 0.02,\n",
      "    \"precipitation\": 0.0,\n",
      "    \"cloud_cover\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from time import strftime\n",
    "from json import dumps\n",
    "\n",
    "def get_forecast(\n",
    "    latitude: float,\n",
    "    longitude: float,\n",
    "    time: str,\n",
    "):\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&hourly=temperature_2m,precipitation_probability,precipitation,cloud_cover&timeformat=unixtime\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    target_epoch = datetime.fromisoformat(time).timestamp()\n",
    "    closest_index = min(range(len(data[\"hourly\"][\"time\"])), key=lambda i: abs(data[\"hourly\"][\"time\"][i] - target_epoch))\n",
    "    \n",
    "    return {\n",
    "        \"temperature\": data[\"hourly\"][\"temperature_2m\"][closest_index],\n",
    "        \"precipitation_probability\": data[\"hourly\"][\"precipitation_probability\"][closest_index]/100,\n",
    "        \"precipitation\": data[\"hourly\"][\"precipitation\"][closest_index],\n",
    "        \"cloud_cover\": data[\"hourly\"][\"cloud_cover\"][closest_index]/100,\n",
    "    }\n",
    "\n",
    "# Example for getting the current forecast for London\n",
    "forecast = get_forecast(51.51, 0.13, strftime(\"%Y-%m-%d %H:%M\"))\n",
    "print(dumps(forecast, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/test_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Metadata: {'system_prompt': \"Your job is to translate the user's input into a weather query. The user may ask about the weather in general, the weather at a specific time, or the weather at a specific location. You should extract the time and location from the user's json and provide a (or part of a) weather query. Reply with the json for the weather query and nothing else.\", 'now': {'external': True}, 'latitude': {'grammar': 'root         ::= coordinate\\ncoordinate   ::= integer \".\" integer\\ninteger      ::= digit | digit digit\\ndigit        ::= \"0\" | \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\"\\n'}, 'longitude': {'grammar': 'root         ::= coordinate\\ncoordinate   ::= integer \".\" integer\\ninteger      ::= digit | digit digit\\ndigit        ::= \"0\" | \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\"\\n'}, 'time': {'grammar': 'root         ::= \"\\\\\"\" date \" \" time \"\\\\\"\"\\ndate         ::= year \"-\" month \"-\" day\\nyear         ::= digit digit digit digit\\nmonth        ::= digit digit\\nday          ::= digit digit\\ntime         ::= hour \":\" minute\\nhour         ::= digit | digit digit\\nminute       ::= digit | digit digit\\ndigit        ::= \"0\" | \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\"\\n'}}\n",
      "Metadata: {'system_prompt': 'Use the provided JSON object to answer the query. Leave out any irrelevant information. Assume the input JSON object is always valid and its information relevant to the query. If the data looks insufficient at face value, try to think step by step to come to a helpful answer. Reply with an answer to the query without mentioning the JSON object or any of its properties.', 'json': {'external': True}, 'thought': None, 'answer': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "{\n",
      "    \"latitude\": 51.51,\n",
      "    \"longitude\": 0.13,\n",
      "    \"time\": \"2024-06-19 22:00\"\n",
      "}\n",
      "\n",
      "Forecast:\n",
      "{\n",
      "    \"temperature\": \"14.5 C\",\n",
      "    \"precipitation_probability\": 0.01,\n",
      "    \"precipitation\": \"0.0 mm\",\n",
      "    \"cloud_cover\": 0.01\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'thought': 'The weather conditions are quite favorable for stargazing tonight, with a low temperature, low precipitation probability, and minimal cloud cover. It should be a great night to get out and enjoy the stars.',\n",
       " 'answer': \"Yes, the weather is perfect for stargazing tonight! The temperature is a comfortable 14.5Â°C, and there's only a 1% chance of precipitation. The cloud cover is also very low, making it an ideal night to get out and enjoy the stars.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PBQA import DB, LLM\n",
    "from time import strftime\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, db: DB, llm: LLM):\n",
    "        self.db = db\n",
    "        self.llm = llm\n",
    "    \n",
    "    def ask_weather(self, input: str):\n",
    "        weather_query = self.llm.ask(\n",
    "            input=input,\n",
    "            pattern=\"weather\",\n",
    "            model=\"llama\",\n",
    "            external={\"now\": strftime(\"%Y-%m-%d %H:%M\")}\n",
    "        )\n",
    "        \n",
    "        print(f\"Query:\\n{dumps(weather_query, indent=4)}\\n\")\n",
    "        \n",
    "        forecast = get_forecast(**weather_query)\n",
    "        forecast[\"temperature\"] = f'{forecast[\"temperature\"]} C'\n",
    "        forecast[\"precipitation\"] = f'{forecast[\"precipitation\"]} mm'\n",
    "        \n",
    "        print(f\"Forecast:\\n{dumps(forecast, indent=4)}\\n\")\n",
    "        \n",
    "        return self.llm.ask(\n",
    "            input=input,\n",
    "            pattern=\"answer_json\",\n",
    "            model=\"llama\",\n",
    "            external={\"json\": dumps(forecast)}\n",
    "        )\n",
    "\n",
    "db = DB(path=\"db\")\n",
    "db.load_pattern(\"weather.yaml\")\n",
    "db.load_pattern(\"answer_json.yaml\")\n",
    "\n",
    "llm = LLM(db=db, host=\"192.168.0.137\")\n",
    "llm.connect_model(\n",
    "    model=\"llama\",\n",
    "    port=8080,\n",
    "    stop=[\"<|eot_id|>\", \"<|start_header_id|>\"],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "agent = Agent(db=db, llm=llm)\n",
    "agent.ask_weather(\"Could I see the stars tonight?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
