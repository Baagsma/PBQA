{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"temperature\": 14.3,\n",
      "    \"precipitation_probability\": 1,\n",
      "    \"precipitation\": 0.0,\n",
      "    \"cloud_cover\": 100\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from time import strftime\n",
    "from json import dumps\n",
    "\n",
    "def get_forecast(\n",
    "    latitude: float,\n",
    "    longitude: float,\n",
    "    time: str,\n",
    "):\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&hourly=temperature_2m,precipitation_probability,precipitation,cloud_cover&timeformat=unixtime\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    target_epoch = datetime.fromisoformat(time).timestamp()\n",
    "    closest_index = min(range(len(data[\"hourly\"][\"time\"])), key=lambda i: abs(data[\"hourly\"][\"time\"][i] - target_epoch))\n",
    "    \n",
    "    return {\n",
    "        \"temperature\": data[\"hourly\"][\"temperature_2m\"][closest_index],\n",
    "        \"precipitation_probability\": data[\"hourly\"][\"precipitation_probability\"][closest_index],\n",
    "        \"precipitation\": data[\"hourly\"][\"precipitation\"][closest_index],\n",
    "        \"cloud_cover\": data[\"hourly\"][\"cloud_cover\"][closest_index],\n",
    "    }\n",
    "\n",
    "# Example for getting the current forecast for London\n",
    "forecast = get_forecast(51.51, 0.13, strftime(\"%Y-%m-%d %H:%M\"))\n",
    "print(dumps(forecast, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "{\n",
      "    \"latitude\": 51.51,\n",
      "    \"longitude\": 0.13,\n",
      "    \"time\": \"2024-06-19 22:00\"\n",
      "}\n",
      "\n",
      "Forecast:\n",
      "{\n",
      "    \"temperature\": \"14.3C\",\n",
      "    \"precipitation_probability\": \"1%\",\n",
      "    \"precipitation\": \"0.0mm\",\n",
      "    \"cloud_cover\": \"100% of the sky\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'thought': \"Unfortunately, the weather conditions don't look favorable for stargazing tonight. The cloud cover is 100% and there's no chance of precipitation, but the temperature is quite cool.\",\n",
       " 'answer': \"Sorry, it doesn't look like you'll be able to see the stars tonight. The cloud cover is 100% and it's not going to be a clear night. Maybe try another night when the skies are clearer.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PBQA import DB, LLM\n",
    "from time import strftime\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, db: DB, llm: LLM):\n",
    "        self.db = db\n",
    "        self.llm = llm\n",
    "    \n",
    "    def ask_weather(self, input: str):\n",
    "        weather_query = self.llm.ask(\n",
    "            input=input,\n",
    "            pattern=\"weather\",\n",
    "            model=\"llama\",\n",
    "            external={\"now\": strftime(\"%Y-%m-%d %H:%M\")}\n",
    "        )\n",
    "        \n",
    "        print(f\"Query:\\n{dumps(weather_query, indent=4)}\\n\")\n",
    "        \n",
    "        forecast = get_forecast(**weather_query)\n",
    "        forecast[\"temperature\"] = f'{forecast[\"temperature\"]}C'\n",
    "        forecast[\"precipitation_probability\"] = f'{forecast[\"precipitation_probability\"]}%'\n",
    "        forecast[\"precipitation\"] = f'{forecast[\"precipitation\"]}mm'\n",
    "        forecast[\"cloud_cover\"] = f'{forecast[\"cloud_cover\"]}% of the sky'\n",
    "        \n",
    "        print(f\"Forecast:\\n{dumps(forecast, indent=4)}\\n\")\n",
    "        \n",
    "        return self.llm.ask(\n",
    "            input=input,\n",
    "            pattern=\"answer_json\",\n",
    "            model=\"llama\",\n",
    "            external={\"json\": dumps(forecast)}\n",
    "        )\n",
    "\n",
    "db = DB(path=\"db\")\n",
    "db.load_pattern(\"weather.yaml\")\n",
    "db.load_pattern(\"answer_json.yaml\")\n",
    "\n",
    "llm = LLM(db=db, host=\"192.168.0.137\")\n",
    "llm.connect_model(\n",
    "    model=\"llama\",\n",
    "    port=8080,\n",
    "    stop=[\"<|eot_id|>\", \"<|start_header_id|>\"],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "agent = Agent(db=db, llm=llm)\n",
    "agent.ask_weather(\"Could I see the stars tonight?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or more readibly,\n",
    "    Sorry, it doesn't look like you'll be able to see the stars tonight. The cloud cover is 100% and it's not going to be a clear night. Maybe try another night when the skies are clearer.\n",
    "\n",
    "Each model has its specific preferences in terms of formatting. In this case for example, I found out that llama3 prefers the unit of the value to be directly next to the value, without any whitespace between."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
